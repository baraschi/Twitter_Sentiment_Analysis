{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "from data_loading import *\n",
    "from data_cleaning import *\n",
    "from utils import *\n",
    "from embeddings import *\n",
    "from prediction import *\n",
    "import itertools\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# load training set as DataFrame\n",
    "train = load_df(TRAIN_NEG, TRAIN_POS, TWEET, LABEL, LABEL_NEG, LABEL_POS)\n",
    "test = pd.DataFrame({TWEET: load_txt(TEST_DATA)})\n",
    "# set patterns to remove, replace, and replace with\n",
    "to_remove = \"<user>\"\n",
    "to_replace = \"[^a-zA-Z#]\"\n",
    "replace_value = \" \"\n",
    "# clean training set\n",
    "#train = clean(train, TWEET, CLEAN_TWEET, to_remove, to_replace, replace_value,option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_clean_options():\n",
    "    all_clean_options = list()\n",
    "    \n",
    "    nb_options = 4\n",
    "    bin_combinations = list(itertools.product([0,1], repeat=nb_options))\n",
    "    \n",
    "    for combination in bin_combinations:\n",
    "        all_clean_options.append({\n",
    "            'duplicates': combination[0],\n",
    "            'replace_pattern': combination[1],\n",
    "            'stop_words': combination[2],\n",
    "            'stemming': combination[3]\n",
    "        })\n",
    "\n",
    "    return all_clean_options\n",
    "    \n",
    "def accuracies(classifiers, train, min_df, min_features, max_features, feature_step, ngram_range):\n",
    "    \"\"\" Iterates on the given parameters range and using the specified classifier, logs accuracies obtained into a\n",
    "    Dataframe\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=['method','n-gram', 'replace_pattern','stop_words','steming','nb_features','accuracy'])\n",
    "    \n",
    "    all_clean_options = generate_all_clean_options()\n",
    "    features_range = np.arange(min_features, max_features, step=feature_step)\n",
    "    \n",
    "    nb_steps = len(all_clean_options) * len(ngram_range) * len(features_range) * len(classifiers)\n",
    "    step = 0\n",
    "    \n",
    "    for clean_options in all_clean_options:\n",
    "        log_msg = '\\033[1m{p:.2f}%\\033[0m ({step}/{nb_step}), cleaning data with {clean_options}...'.format(\n",
    "            clean_options= clean_options,\n",
    "            p = 100 * (step / nb_steps),\n",
    "            step = step + 1,\n",
    "            nb_step = nb_steps\n",
    "        )\n",
    "        printOver(log_msg)\n",
    "    \n",
    "        train_new = clean(train, TWEET, CLEAN_TWEET, to_remove, to_replace, replace_value,clean_options)\n",
    "\n",
    "        for classifier_str in classifiers:\n",
    "            if classifier_str is \"tfidf\":\n",
    "                classifier = classify_tfidf\n",
    "            elif classifier_str is \"bow\":\n",
    "                classifier = classify_bow\n",
    "            else:\n",
    "                raise Exception(\"Unsupported classify method: \"+classifier_str)\n",
    "                \n",
    "            for ngram in ngram_range: \n",
    "                for nb_features in features_range:\n",
    "                    log_msg = '\\033[1m{p:.2f}%\\033[0m ({step}/{nb_step}), classifying with {classifier}, {clean_options}...'.format(\n",
    "                        classifier = classifier_str,\n",
    "                        clean_options= clean_options,\n",
    "                        p = 100 * (step / nb_steps),\n",
    "                        step = step + 1,\n",
    "                        nb_step = nb_steps\n",
    "                    )\n",
    "                    printOver(log_msg)\n",
    "\n",
    "                    accuracy = classifier(train_new, None, tweets_col = CLEAN_TWEET, ngram_range=ngram, max_features =nb_features, min_df=min_df)\n",
    "                    df = df.append({\n",
    "                        'method': classifier.__name__, \n",
    "                        'n-gram': ngram[1], \n",
    "                        'duplicates': clean_options['duplicates'],\n",
    "                        'replace_pattern': clean_options['replace_pattern'],\n",
    "                        'stop_words': clean_options['stop_words'],\n",
    "                        'stemming': clean_options['stemming'],\n",
    "                        'nb_features': nb_features,\n",
    "                        'accuracy': accuracy\n",
    "                    }, ignore_index=True)\n",
    "                    step = step + 1\n",
    "                    \n",
    "    log_msg = '\\033[1mDone!\\033[0m ({step}/{nb_step})'.format(\n",
    "            p = 100 * (step / nb_steps),\n",
    "            step = step,\n",
    "            nb_step = nb_steps\n",
    "    )\n",
    "    printOver(log_msg)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m0.00%\u001b[0m (1/960), classifying with bow, {'duplicates': 0, 'replace_pattern': 0, 'stop_words': 0, 'stemming': 0}..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d1619c96ee09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m110000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfeature_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-8-150341b0cb1b>\u001b[0m in \u001b[0;36maccuracies\u001b[1;34m(classifiers, train, min_df, min_features, max_features, feature_step, ngram_range)\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[0mprintOver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweets_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCLEAN_TWEET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mngram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnb_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m                     df = df.append({\n\u001b[0;32m     61\u001b[0m                         \u001b[1;34m'method'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Docs\\GitHub\\ML_Project_2\\prediction.py\u001b[0m in \u001b[0;36mclassify_bow\u001b[1;34m(train, test, tweets_col, filename, max_df, min_df, max_features, ngram_range)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mxtrain_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxvalid_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mlreg_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mlreg_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_bow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mprediction_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlreg_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvalid_bow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# predicting on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_validation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    891\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = accuracies(\n",
    "    [\"bow\", \"tfidf\"],\n",
    "    train = train,\n",
    "    min_df=1, \n",
    "    min_features=10000, \n",
    "    max_features=110000,\n",
    "    feature_step=10000, \n",
    "    ngram_range=[(1,1), (1,2), (1,3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDone!\u001b[0m (32/32)), classifying with tfidf, {'duplicates': 1, 'replace_pattern': 1, 'stop_words': 1, 'stemming': 1}...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = accuracies(\n",
    "    [\"bow\", \"tfidf\"],\n",
    "    train = train,\n",
    "    min_df=1, \n",
    "    min_features=10000, \n",
    "    max_features=11000,\n",
    "    feature_step=10000, \n",
    "    ngram_range=[(1,1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>n-gram</th>\n",
       "      <th>replace_pattern</th>\n",
       "      <th>stop_words</th>\n",
       "      <th>steming</th>\n",
       "      <th>nb_features</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.788283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.787867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.790567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.790383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.785083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.784250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.784650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.783650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.790733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.790517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.783583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.783717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.783067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.775504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.771110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.770982</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.770320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.770320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.774144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.773463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.775431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.776001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.770614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.769952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>classify_bow</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.769603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>classify_tfidf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.770099</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method n-gram replace_pattern stop_words  steming nb_features  \\\n",
       "0     classify_bow      1               0          0      NaN       10000   \n",
       "1   classify_tfidf      1               0          0      NaN       10000   \n",
       "2     classify_bow      1               0          0      NaN       10000   \n",
       "3   classify_tfidf      1               0          0      NaN       10000   \n",
       "4     classify_bow      1               0          1      NaN       10000   \n",
       "5   classify_tfidf      1               0          1      NaN       10000   \n",
       "6     classify_bow      1               0          1      NaN       10000   \n",
       "7   classify_tfidf      1               0          1      NaN       10000   \n",
       "8     classify_bow      1               1          0      NaN       10000   \n",
       "9   classify_tfidf      1               1          0      NaN       10000   \n",
       "10    classify_bow      1               1          0      NaN       10000   \n",
       "11  classify_tfidf      1               1          0      NaN       10000   \n",
       "12    classify_bow      1               1          1      NaN       10000   \n",
       "13  classify_tfidf      1               1          1      NaN       10000   \n",
       "14    classify_bow      1               1          1      NaN       10000   \n",
       "15  classify_tfidf      1               1          1      NaN       10000   \n",
       "16    classify_bow      1               0          0      NaN       10000   \n",
       "17  classify_tfidf      1               0          0      NaN       10000   \n",
       "18    classify_bow      1               0          0      NaN       10000   \n",
       "19  classify_tfidf      1               0          0      NaN       10000   \n",
       "20    classify_bow      1               0          1      NaN       10000   \n",
       "21  classify_tfidf      1               0          1      NaN       10000   \n",
       "22    classify_bow      1               0          1      NaN       10000   \n",
       "23  classify_tfidf      1               0          1      NaN       10000   \n",
       "24    classify_bow      1               1          0      NaN       10000   \n",
       "25  classify_tfidf      1               1          0      NaN       10000   \n",
       "26    classify_bow      1               1          0      NaN       10000   \n",
       "27  classify_tfidf      1               1          0      NaN       10000   \n",
       "28    classify_bow      1               1          1      NaN       10000   \n",
       "29  classify_tfidf      1               1          1      NaN       10000   \n",
       "30    classify_bow      1               1          1      NaN       10000   \n",
       "31  classify_tfidf      1               1          1      NaN       10000   \n",
       "\n",
       "    accuracy  duplicates  stemming  \n",
       "0   0.788283         0.0       0.0  \n",
       "1   0.787867         0.0       0.0  \n",
       "2   0.790567         0.0       1.0  \n",
       "3   0.790383         0.0       1.0  \n",
       "4   0.785083         0.0       0.0  \n",
       "5   0.784250         0.0       0.0  \n",
       "6   0.784650         0.0       1.0  \n",
       "7   0.783650         0.0       1.0  \n",
       "8   0.787933         0.0       0.0  \n",
       "9   0.787500         0.0       0.0  \n",
       "10  0.790733         0.0       1.0  \n",
       "11  0.790517         0.0       1.0  \n",
       "12  0.784300         0.0       0.0  \n",
       "13  0.783583         0.0       0.0  \n",
       "14  0.783717         0.0       1.0  \n",
       "15  0.783067         0.0       1.0  \n",
       "16  0.774272         1.0       0.0  \n",
       "17  0.772930         1.0       0.0  \n",
       "18  0.775137         1.0       1.0  \n",
       "19  0.775504         1.0       1.0  \n",
       "20  0.771110         1.0       0.0  \n",
       "21  0.770982         1.0       0.0  \n",
       "22  0.770320         1.0       1.0  \n",
       "23  0.770320         1.0       1.0  \n",
       "24  0.774144         1.0       0.0  \n",
       "25  0.773463         1.0       0.0  \n",
       "26  0.775431         1.0       1.0  \n",
       "27  0.776001         1.0       1.0  \n",
       "28  0.770614         1.0       0.0  \n",
       "29  0.769952         1.0       0.0  \n",
       "30  0.769603         1.0       1.0  \n",
       "31  0.770099         1.0       1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(accs_clean, accs_noclean, legends, colors, title, axis_labels, filename):\n",
    "    nb_plots = len(accs_clean)\n",
    "    plotable_df_clean = accs_clean.transpose()\n",
    "    plotable_df_clean['nfeatures'] = plotable_df_clean.index\n",
    "\n",
    "    plotable_df_noclean = accs_noclean.transpose()\n",
    "    plotable_df_noclean['nfeatures'] = plotable_df_noclean.index\n",
    "        \n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    for i in range(0, nb_plots):\n",
    "        plt.plot(plotable_df_clean[i].index, plotable_df_clean[i].values,label=legends[i] + ' (clean)',color=colors[i])\n",
    "        plt.plot(plotable_df_noclean[i].index, plotable_df_noclean[i].values,label=legends[i],color=colors[i], linestyle=':')\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel(axis_labels[0])\n",
    "    plt.ylabel(axis_labels[1])\n",
    "    plt.legend()\n",
    "    \n",
    "    if not os.path.exists(PLOTS_FOLDER):\n",
    "        os.makedirs(PLOTS_FOLDER)\n",
    "    plt.savefig(PLOTS_FOLDER + filename + '.pdf') #pdf is a better choice than png as it is vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(\n",
    "    bow_accs_clean,\n",
    "    bow_accs_noclean,\n",
    "    legends = ['unigram bow vectorizer', 'bigram bow vectorizer', 'trigram bow vectorizer'],\n",
    "    colors = ['royalblue', 'orangered', 'gold'],\n",
    "    title = 'Accuracy BOW N-gram(1~3)',\n",
    "    axis_labels =['Number of features','Validation set accuracy'],\n",
    "    filename = \"plot_bow\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
