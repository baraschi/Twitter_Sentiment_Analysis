{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "from data_loading import *\n",
    "from data_cleaning import *\n",
    "from utils import *\n",
    "from embeddings import *\n",
    "from prediction import *\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "# load training set as DataFrame\n",
    "train = load_df(TRAIN_NEG, TRAIN_POS, TWEET, LABEL, LABEL_NEG, LABEL_POS)\n",
    "test = pd.DataFrame({TWEET: load_txt(TEST_DATA)})\n",
    "# set patterns to remove, replace, and replace with\n",
    "to_remove = \"<user>\"\n",
    "to_replace = \"[^a-zA-Z#]\"\n",
    "replace_value = \" \"\n",
    "# clean training set\n",
    "#train = clean(train, TWEET, CLEAN_TWEET, to_remove, to_replace, replace_value,option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_clean_options():\n",
    "    all_clean_options = list()\n",
    "    \n",
    "\n",
    "    for i in range(0,2) :\n",
    "        for j in range(0,2) :\n",
    "            for k in range(0,2) :\n",
    "                all_clean_options.append({\n",
    "                    'replace_pattern': i,\n",
    "                    'stop_words': j,\n",
    "                    'steming': k\n",
    "                })\n",
    "    \n",
    "    return all_clean_options\n",
    "    \n",
    "def accuracies(classifiers, train, min_df, min_features, max_features, feature_step, ngram_range):\n",
    "    \"\"\" Iterates on the given parameters range and using the specified classifier, logs accuracies obtained into a\n",
    "    Dataframe\"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(columns=['method','n-gram', 'replace_pattern','stop_words','steming','nb_features','accuracy'])\n",
    "    \n",
    "    all_clean_options = generate_all_clean_options()\n",
    "    features_range = np.arange(min_features, max_features, step=feature_step)\n",
    "    \n",
    "    nb_steps = len(all_clean_options) * len(ngram_range) * len(features_range) * len(classifiers)\n",
    "    step = 0\n",
    "    \n",
    "    for clean_options in all_clean_options:\n",
    "        log_msg = '\\033[1m{p:.2f}%\\033[0m ({step}/{nb_step}), cleaning data with {clean_options}...'.format(\n",
    "            clean_options= clean_options,\n",
    "            p = 100 * (step / nb_steps),\n",
    "            step = step + 1,\n",
    "            nb_step = nb_steps\n",
    "        )\n",
    "        printOver(log_msg)\n",
    "    \n",
    "        train = clean(train, TWEET, CLEAN_TWEET, to_remove, to_replace, replace_value,clean_options)\n",
    "\n",
    "        for classifier_str in classifiers:\n",
    "            if classifier_str is \"tfidf\":\n",
    "                classifier = classify_tfidf\n",
    "            elif classifier_str is \"bow\":\n",
    "                classifier = classify_bow\n",
    "            else:\n",
    "                raise Exception(\"Unsupported classify method: \"+classifier_str)\n",
    "                \n",
    "            for ngram in ngram_range: \n",
    "                for nb_features in features_range:\n",
    "                    log_msg = '\\033[1m{p:.2f}%\\033[0m ({step}/{nb_step}), classifying with {classifier}, {clean_options}...'.format(\n",
    "                        classifier = classifier_str,\n",
    "                        clean_options= clean_options,\n",
    "                        p = 100 * (step / nb_steps),\n",
    "                        step = step + 1,\n",
    "                        nb_step = nb_steps\n",
    "                    )\n",
    "                    printOver(log_msg)\n",
    "\n",
    "                    accuracy = classifier(train, None, tweets_col = CLEAN_TWEET, ngram_range=ngram, max_features =nb_features, min_df=min_df)\n",
    "                    df = df.append({\n",
    "                        'method': classifier.__name__, \n",
    "                        'n-gram': ngram[1], \n",
    "                        'replace_pattern': clean_options['replace_pattern'],\n",
    "                        'stop_words': clean_options['stop_words'],\n",
    "                        'steming': clean_options['steming'],\n",
    "                        'nb_features': nb_features,\n",
    "                        'accuracy': accuracy\n",
    "                    }, ignore_index=True)\n",
    "                    step = step + 1\n",
    "                    \n",
    "    log_msg = '\\033[1mDone!\\033[0m ({step}/{nb_step})'.format(\n",
    "            p = 100 * (step / nb_steps),\n",
    "            step = step,\n",
    "            nb_step = nb_steps\n",
    "    )\n",
    "    printOver(log_msg)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35.62%\u001b[0m (172/480), classifying with tfidf, {'replace_pattern': 0, 'stop_words': 1, 'steming': 0}..."
     ]
    }
   ],
   "source": [
    "df = accuracies(\n",
    "    [\"bow\", \"tfidf\"],\n",
    "    train = train,\n",
    "    min_df=1, \n",
    "    min_features=10000, \n",
    "    max_features=110000,\n",
    "    feature_step=10000, \n",
    "    ngram_range=[(1,1), (1,2), (1,3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
